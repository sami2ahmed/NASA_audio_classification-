{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: brief notebook that helped me quickly web scrape hundreds of hours of audio from NASA (well, technically University of Iowa) \n",
    "# Main topics covered: Web scraping (BeautifulSoup) \n",
    "# Date: 2/7/2019\n",
    "# Author: Sami Ahmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas \n",
    "import pandas as pd\n",
    "\n",
    "# webscraping and regular expressions\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# suppress long warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response is good, we can hit that endpoint \n",
    "url = 'https://emfisis.physics.uiowa.edu/Events/rbsp-a/burst/'\n",
    "response = requests.get(url)\n",
    "response.status_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all text from page \n",
    "page = response.text\n",
    "soup = BeautifulSoup(page, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *WARNING* Not necessary for my investigation; however, below are a few good ways to isolate parts of a website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"?C=N;O=D\">Name</a>\n",
      "<a href=\"?C=M;O=A\">Last modified</a>\n",
      "<a href=\"?C=S;O=A\">Size</a>\n",
      "<a href=\"?C=D;O=A\">Description</a>\n",
      "<a href=\"/rbsp/audio/mp3/\">Parent Directory</a>\n",
      "<a href=\"2012/\">2012/</a>\n",
      "<a href=\"2013/\">2013/</a>\n",
      "<a href=\"2014/\">2014/</a>\n",
      "<a href=\"2015/\">2015/</a>\n",
      "<a href=\"2016/\">2016/</a>\n",
      "<a href=\"2017/\">2017/</a>\n",
      "<a href=\"2018/\">2018/</a>\n",
      "<a href=\"2019/\">2019/</a>\n"
     ]
    }
   ],
   "source": [
    "for link in soup_audio.find_all('a'): \n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_detail = [audio for audio in soup.find_all('a') if 'rbsp-a_burst_times' in str(audio)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links_audio =  []\n",
    "for links in soup_audio.find_all('a'): \n",
    "    all_links_audio.append(links['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete uneeded items at beginning of list\n",
    "del all_links_audio[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2012/', '2013/', '2014/', '2015/', '2016/', '2017/', '2018/', '2019/']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_links_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *WARNING* Investigation resuming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDITONAL WARNING \n",
    "### If you run the run the code below it will take a very long time, you might not have memory adequate to store all the data on your computer. If you run into this issue, refer to my guide on how to run your code on an AWS EC2 (virtual machine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_url = 'https://space.physics.uiowa.edu/rbsp/audio/mp3/L2A/2017/01/01/'\n",
    "file_url = 'https://space.physics.uiowa.edu/rbsp/audio/mp3/L2A/2017/01/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigates to the nested folder structure in order to download each individual .mp3 (at scale) \n",
    "# I use this function in \"crawler\" function below\n",
    "def deeper(file_url):\n",
    "    get_data = (requests.get(file_url, verify=False).content)\n",
    "    soup_page = BeautifulSoup(get_data, \"lxml\")\n",
    "    all_links_audio =  []\n",
    "    for links in soup_page.find_all('a'): \n",
    "        all_links_audio.append(links['href'])\n",
    "    regex = re.compile(r'[0-9]+/|.*mp3$')    \n",
    "    selected_files = list(filter(regex.match, all_links_audio))\n",
    "    return selected_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters through all the files to only retrieve files of extension .mp3 \n",
    "def crawler(links):\n",
    "    newlinks = []\n",
    "    regex = re.compile(r'.*mp3$')\n",
    "    regex2 = re.compile(r'/$')\n",
    "    if len(list(filter(regex.match,links)))==len(links):\n",
    "        return links\n",
    "    for link in links:\n",
    "        if regex.match(link):\n",
    "            newlinks.append(link)\n",
    "        else:\n",
    "            deep = deeper(link)\n",
    "            newlinks.extend([link+step for step in deep])\n",
    "    return crawler(newlinks)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3s_2013 = crawler(['https://space.physics.uiowa.edu/rbsp/audio/mp3/L2A/2013/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mp3's to pickle for use in separate notebook \n",
    "with open('all_mp3s_L2A.pkl', 'wb') as f:\n",
    "    pickle.dump(mp3s_2013, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
